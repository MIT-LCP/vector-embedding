# dicom_bottleneck_profiler.py - æ—¢å­˜DICOMå‡¦ç†ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š

import pydicom as dicom
import time
import numpy as np
import torch
import cv2
import os
from functools import wraps

def profile_function(func_name):
    """é–¢æ•°ã®å®Ÿè¡Œæ™‚é–“ã‚’æ¸¬å®šã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            print(f"  {func_name}: {end_time - start_time:.4f}s")
            return result, end_time - start_time
        return wrapper
    return decorator

class DICOMProcessingProfiler:
    """DICOMå‡¦ç†ã®è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
    
    def __init__(self):
        self.timing_stats = {}
    
    def profile_dicom_processing_steps(self, dicom_path, target_frames=16, target_size=(224, 224)):
        """DICOMå‡¦ç†ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©³ç´°ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
        
        print(f"\nğŸ” PROFILING DICOM PROCESSING: {os.path.basename(dicom_path)}")
        print("-" * 60)
        
        total_start = time.time()
        
        # Step 1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        @profile_function("1. dicom.dcmread()")
        def read_dicom():
            return dicom.dcmread(dicom_path)
        
        dcm, read_time = read_dicom()
        
        # Step 2: pixel_arrayå–å¾—
        @profile_function("2. .pixel_array access")
        def get_pixel_array():
            return dcm.pixel_array
        
        pixel_array, pixel_time = get_pixel_array()
        
        print(f"  â””â”€ Original shape: {pixel_array.shape}")
        print(f"  â””â”€ Data type: {pixel_array.dtype}")
        print(f"  â””â”€ Value range: {pixel_array.min():.1f} - {pixel_array.max():.1f}")
        
        # Step 3: ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
        @profile_function("3. Data type conversion")
        def convert_dtype():
            return pixel_array.astype(np.float32)
        
        pixel_float, convert_time = convert_dtype()
        
        # Step 4: æ­£è¦åŒ–
        @profile_function("4. Normalization")
        def normalize():
            if pixel_float.max() > 1:
                return (pixel_float - pixel_float.min()) / (pixel_float.max() - pixel_float.min())
            return pixel_float
        
        normalized, norm_time = normalize()
        
        # Step 5: æ¬¡å…ƒå‡¦ç†ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ è»¸ã®å‡¦ç†ï¼‰
        @profile_function("5. Frame dimension handling")
        def handle_frames():
            if normalized.ndim == 2:
                # 2D -> 3D (é™æ­¢ç”»ã‚’å‹•ç”»ã«)
                return np.stack([normalized] * target_frames, axis=0)
            elif normalized.ndim == 3:
                # æ—¢ã«3D
                if normalized.shape[0] > target_frames:
                    # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°å‰Šæ¸›
                    indices = np.linspace(0, normalized.shape[0]-1, target_frames, dtype=int)
                    return normalized[indices]
                elif normalized.shape[0] < target_frames:
                    # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°å¢—åŠ 
                    padding = target_frames - normalized.shape[0]
                    last_frame = normalized[-1:]
                    padding_frames = np.repeat(last_frame, padding, axis=0)
                    return np.concatenate([normalized, padding_frames], axis=0)
                else:
                    return normalized
            else:
                return normalized[:target_frames] if normalized.shape[0] >= target_frames else normalized
        
        frames_processed, frame_time = handle_frames()
        print(f"  â””â”€ After frame processing: {frames_processed.shape}")
        
        # Step 6: ãƒªã‚µã‚¤ã‚ºå‡¦ç†
        @profile_function("6. Resize processing")
        def resize_frames():
            resized_frames = []
            for i, frame in enumerate(frames_processed):
                if len(frame.shape) == 2:
                    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ« -> RGB
                    frame_rgb = np.stack([frame] * 3, axis=-1)
                else:
                    frame_rgb = frame
                
                # ãƒªã‚µã‚¤ã‚º
                frame_resized = cv2.resize(frame_rgb, target_size)
                resized_frames.append(frame_resized)
            
            return np.stack(resized_frames, axis=0)
        
        resized_array, resize_time = resize_frames()
        print(f"  â””â”€ After resize: {resized_array.shape}")
        
        # Step 7: ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
        @profile_function("7. Tensor conversion")
        def convert_to_tensor():
            # (T, H, W, C) -> (C, T, H, W)
            return torch.from_numpy(resized_array).permute(3, 0, 1, 2).float()
        
        final_tensor, tensor_time = convert_to_tensor()
        print(f"  â””â”€ Final tensor: {final_tensor.shape}")
        
        total_time = time.time() - total_start
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        steps_times = {
            'read_dicom': read_time,
            'pixel_array': pixel_time,
            'dtype_convert': convert_time,
            'normalize': norm_time,
            'frame_handling': frame_time,
            'resize': resize_time,
            'tensor_convert': tensor_time
        }
        
        print(f"\nğŸ“Š TIMING BREAKDOWN:")
        print(f"  Total time: {total_time:.4f}s")
        print("-" * 40)
        
        for step, step_time in steps_times.items():
            percentage = (step_time / total_time) * 100
            print(f"  {step:15s}: {step_time:.4f}s ({percentage:5.1f}%)")
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
        max_time_step = max(steps_times.items(), key=lambda x: x[1])
        print(f"\nğŸ”¥ BOTTLENECK: {max_time_step[0]} ({max_time_step[1]:.4f}s)")
        
        return {
            'total_time': total_time,
            'steps': steps_times,
            'bottleneck': max_time_step,
            'final_tensor': final_tensor
        }
    
    def compare_optimization_strategies(self, dicom_path):
        """æœ€é©åŒ–æˆ¦ç•¥ã®æ¯”è¼ƒ"""
        
        print(f"\nğŸš€ OPTIMIZATION STRATEGIES COMPARISON")
        print("=" * 60)
        
        # æˆ¦ç•¥1: ç¾åœ¨ã®æ–¹æ³•ï¼ˆè©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        print(f"\n1ï¸âƒ£ Current method (detailed profiling):")
        current_result = self.profile_dicom_processing_steps(dicom_path)
        
        # æˆ¦ç•¥2: æœ€é©åŒ–ã•ã‚ŒãŸæ­£è¦åŒ–
        print(f"\n2ï¸âƒ£ Optimized normalization:")
        start_time = time.time()
        
        dcm = dicom.dcmread(dicom_path)
        pixel_array = dcm.pixel_array
        
        # æœ€é©åŒ–: ä¸€åº¦ã«æ­£è¦åŒ–
        if pixel_array.dtype != np.float32:
            pixel_array = pixel_array.astype(np.float32)
        
        # Min/Maxã‚’ä¸€åº¦ã ã‘è¨ˆç®—
        pmin, pmax = pixel_array.min(), pixel_array.max()
        if pmax > 1:
            pixel_array = (pixel_array - pmin) / (pmax - pmin)
        
        opt_norm_time = time.time() - start_time
        print(f"  Optimized normalization: {opt_norm_time:.4f}s")
        
        # æˆ¦ç•¥3: ãƒãƒƒãƒãƒªã‚µã‚¤ã‚º
        print(f"\n3ï¸âƒ£ Batch resize strategy:")
        start_time = time.time()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
        if pixel_array.ndim == 2:
            frames = np.stack([pixel_array] * 16, axis=0)
        else:
            frames = pixel_array[:16] if pixel_array.shape[0] >= 16 else pixel_array
        
        # ãƒãƒƒãƒã§ãƒªã‚µã‚¤ã‚ºï¼ˆã‚ˆã‚ŠåŠ¹ç‡çš„ï¼‰
        if len(frames.shape) == 3:
            # (T, H, W) -> (T, H, W, 3)
            frames_rgb = np.stack([frames] * 3, axis=-1)
        else:
            frames_rgb = frames
        
        # ä¸€åº¦ã«ã™ã¹ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒªã‚µã‚¤ã‚º
        resized_batch = []
        for frame in frames_rgb:
            resized_batch.append(cv2.resize(frame, (224, 224)))
        
        batch_resize_time = time.time() - start_time
        print(f"  Batch resize: {batch_resize_time:.4f}s")
        
        # æˆ¦ç•¥4: ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå‡¦ç†
        print(f"\n4ï¸âƒ£ Memory efficient processing:")
        start_time = time.time()
        
        dcm = dicom.dcmread(dicom_path)
        
        # ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹æ“ä½œã§ãƒ¡ãƒ¢ãƒªç¯€ç´„
        pixel_array = dcm.pixel_array
        
        # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã¨ãƒªã‚µã‚¤ã‚ºã‚’çµ„ã¿åˆã‚ã›
        if pixel_array.ndim == 2:
            # ç›´æ¥ãƒªã‚µã‚¤ã‚º
            resized = cv2.resize(pixel_array.astype(np.float32), (224, 224))
            # æ­£è¦åŒ–
            if resized.max() > 1:
                resized = (resized - resized.min()) / (resized.max() - resized.min())
            # RGBåŒ–ã¨ãƒ•ãƒ¬ãƒ¼ãƒ è¤‡è£½
            frames = np.stack([np.stack([resized] * 3, axis=-1)] * 16, axis=0)
        
        # ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
        tensor = torch.from_numpy(frames).permute(3, 0, 1, 2).float()
        
        memory_eff_time = time.time() - start_time
        print(f"  Memory efficient: {memory_eff_time:.4f}s")
        
        # çµæœæ¯”è¼ƒ
        print(f"\nğŸ“ˆ COMPARISON RESULTS:")
        print("-" * 40)
        
        methods = [
            ("Current method", current_result['total_time']),
            ("Optimized normalization", opt_norm_time),
            ("Batch resize", batch_resize_time),
            ("Memory efficient", memory_eff_time)
        ]
        
        best_time = min(time for _, time in methods)
        
        for name, time_val in methods:
            speedup = current_result['total_time'] / time_val
            improvement = "ğŸ“ˆ" if time_val < current_result['total_time'] else "ğŸ“‰"
            print(f"  {name:20s}: {time_val:.4f}s (Ã—{speedup:.1f}) {improvement}")
        
        return {
            'current': current_result['total_time'],
            'optimized_norm': opt_norm_time,
            'batch_resize': batch_resize_time,
            'memory_efficient': memory_eff_time
        }
    
    def analyze_memory_usage(self, dicom_path):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æ"""
        print(f"\nğŸ’¾ MEMORY USAGE ANALYSIS")
        print("=" * 40)
        
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        print(f"Initial memory: {initial_memory:.1f}MB")
        
        # Step 1: DICOMèª­ã¿è¾¼ã¿
        dcm = dicom.dcmread(dicom_path)
        after_read = process.memory_info().rss / 1024 / 1024
        print(f"After dcmread: {after_read:.1f}MB (+{after_read-initial_memory:.1f}MB)")
        
        # Step 2: pixel_arrayå–å¾—
        pixel_array = dcm.pixel_array
        after_pixel = process.memory_info().rss / 1024 / 1024
        print(f"After pixel_array: {after_pixel:.1f}MB (+{after_pixel-after_read:.1f}MB)")
        print(f"  Array size: {pixel_array.nbytes / 1024 / 1024:.1f}MB")
        
        # Step 3: å‡¦ç†å¾Œ
        if pixel_array.ndim == 2:
            frames = np.stack([pixel_array.astype(np.float32)] * 16, axis=0)
        
        after_process = process.memory_info().rss / 1024 / 1024
        print(f"After processing: {after_process:.1f}MB (+{after_process-after_pixel:.1f}MB)")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del dcm, pixel_array
        gc.collect()
        
        after_cleanup = process.memory_info().rss / 1024 / 1024
        print(f"After cleanup: {after_cleanup:.1f}MB ({after_cleanup-initial_memory:+.1f}MB)")

def generate_optimized_dicom_loader():
    """æœ€é©åŒ–ã•ã‚ŒãŸDICOMãƒ­ãƒ¼ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
    
    code = '''
def load_dicom_optimized(dicom_path, target_frames=16, target_size=(224, 224)):
    """æœ€é©åŒ–ã•ã‚ŒãŸDICOMèª­ã¿è¾¼ã¿"""
    
    # 1. é«˜é€Ÿèª­ã¿è¾¼ã¿
    dcm = dicom.dcmread(dicom_path)
    pixel_array = dcm.pixel_array
    
    # 2. åŠ¹ç‡çš„ãªå‹å¤‰æ›ã¨æ­£è¦åŒ–
    if pixel_array.dtype != np.float32:
        pixel_array = pixel_array.astype(np.float32)
    
    # Min/Maxã‚’ä¸€åº¦ã ã‘è¨ˆç®—
    if pixel_array.max() > 1:
        pmin, pmax = pixel_array.min(), pixel_array.max()
        pixel_array = (pixel_array - pmin) / (pmax - pmin)
    
    # 3. åŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
    if pixel_array.ndim == 2:
        # 2D: ç›´æ¥ãƒªã‚µã‚¤ã‚ºã—ã¦ã‹ã‚‰è¤‡è£½
        resized_frame = cv2.resize(pixel_array, target_size)
        frames_rgb = np.stack([resized_frame] * 3, axis=-1)  # RGBåŒ–
        video_array = np.stack([frames_rgb] * target_frames, axis=0)  # ãƒ•ãƒ¬ãƒ¼ãƒ è¤‡è£½
    
    elif pixel_array.ndim == 3:
        # 3D: ãƒ•ãƒ¬ãƒ¼ãƒ æ•°èª¿æ•´
        if pixel_array.shape[0] != target_frames:
            if pixel_array.shape[0] > target_frames:
                indices = np.linspace(0, pixel_array.shape[0]-1, target_frames, dtype=int)
                pixel_array = pixel_array[indices]
            else:
                # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                padding = target_frames - pixel_array.shape[0]
                last_frames = np.repeat(pixel_array[-1:], padding, axis=0)
                pixel_array = np.concatenate([pixel_array, last_frames], axis=0)
        
        # ãƒãƒƒãƒãƒªã‚µã‚¤ã‚º
        resized_frames = []
        for frame in pixel_array:
            frame_rgb = np.stack([frame] * 3, axis=-1) if len(frame.shape) == 2 else frame
            resized_frames.append(cv2.resize(frame_rgb, target_size))
        
        video_array = np.stack(resized_frames, axis=0)
    
    # 4. ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
    video_tensor = torch.from_numpy(video_array).permute(3, 0, 1, 2).float()
    
    return video_tensor
'''
    
    return code

def run_comprehensive_dicom_analysis(dicom_path):
    """åŒ…æ‹¬çš„ãªDICOMåˆ†æ"""
    
    profiler = DICOMProcessingProfiler()
    
    print("ğŸ” COMPREHENSIVE DICOM PROCESSING ANALYSIS")
    print("=" * 70)
    
    # 1. è©³ç´°ã‚¹ãƒ†ãƒƒãƒ—åˆ†æ
    step_analysis = profiler.profile_dicom_processing_steps(dicom_path)
    
    # 2. æœ€é©åŒ–æˆ¦ç•¥æ¯”è¼ƒ
    optimization_results = profiler.compare_optimization_strategies(dicom_path)
    
    # 3. ãƒ¡ãƒ¢ãƒªåˆ†æ
    profiler.analyze_memory_usage(dicom_path)
    
    # 4. æœ€é©åŒ–ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    optimized_code = generate_optimized_dicom_loader()
    
    # 5. æ¨å¥¨äº‹é …
    print(f"\nğŸ¯ OPTIMIZATION RECOMMENDATIONS:")
    print("=" * 50)
    
    bottleneck_step = step_analysis['bottleneck'][0]
    bottleneck_time = step_analysis['bottleneck'][1]
    
    recommendations = []
    
    if 'resize' in bottleneck_step and bottleneck_time > 0.01:
        recommendations.append("ğŸ”¥ Resize is the bottleneck - consider batch processing")
    
    if 'pixel_array' in bottleneck_step:
        recommendations.append("ğŸ”¥ Pixel array access is slow - DICOM file may be compressed")
    
    if 'normalize' in bottleneck_step:
        recommendations.append("ğŸ”¥ Normalization is slow - optimize min/max computation")
    
    if step_analysis['total_time'] > 1.0:
        recommendations.append("ğŸš¨ Overall processing is very slow - multiple optimizations needed")
    
    # æœ€å¤§ã®æ”¹å–„åŠ¹æœã‚’ç‰¹å®š
    best_optimization = min(optimization_results.items(), key=lambda x: x[1])
    improvement = optimization_results['current'] / best_optimization[1]
    
    recommendations.append(f"âœ… Best optimization: {best_optimization[0]} ({improvement:.1f}x speedup)")
    
    for rec in recommendations:
        print(f"  {rec}")
    
    return {
        'step_analysis': step_analysis,
        'optimization_results': optimization_results,
        'optimized_code': optimized_code,
        'recommendations': recommendations
    }

if __name__ == "__main__":
    # ã‚µãƒ³ãƒ—ãƒ«DICOMãƒ•ã‚¡ã‚¤ãƒ«
    sample_dicom = "/mnt/s/Workfolder/Physionet/mimic-iv-echo/0.1/p10/p10002221/s94106955/94106955_0001.dcm"
    
    if os.path.exists(sample_dicom):
        results = run_comprehensive_dicom_analysis(sample_dicom)
        
        print(f"\nğŸ“ OPTIMIZED CODE:")
        print("=" * 40)
        print(results['optimized_code'])
        
    else:
        print("âŒ Sample DICOM file not found")
        print("Please update the path to your DICOM file")