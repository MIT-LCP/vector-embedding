# step02_ve_extraction_quickfix.py
# æœ€å°é™ã®ä¿®æ­£ç‰ˆ

import torch
import torchvision
import pandas as pd
import numpy as np
from tqdm import tqdm
import sys

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
sys.path.insert(0, "vector-embedding/echo/module/veecho")
from model_utils import EchoEmbeddingModel, TrainingConfig
import data_utils

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def load_trained_model(finetuned_model=True, model_file="best_echo_model.pth"):
    # Step01ã¨åŒã˜è¨­å®š
    config = TrainingConfig(
        use_adversarial=True, 
        adversarial_attributes=['Sex', 'Race'],
        lambda_adv=1.0, 
        dynamic_lambda=True, 
        use_lora=True, 
        lora_r=8
    )
    
    # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    checkpoint = torch.load("/mnt/s/Workfolder/vector_embedding_echo/model/echoprime/echo_prime_encoder.pt", 
                           map_location=device)
    echo_encoder = torchvision.models.video.mvit_v2_s()
    echo_encoder.head[-1] = torch.nn.Linear(echo_encoder.head[-1].in_features, 512)
    echo_encoder.load_state_dict(checkpoint)
    
    # è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    model = EchoEmbeddingModel(echo_encoder, config)
    
    # è¨“ç·´æ¸ˆã¿é‡ã¿ã®èª­ã¿è¾¼ã¿åˆ¤å®š
    if finetuned_model:
        try:
            model_path = '/mnt/s/Workfolder/vector_embedding_echo/model/domain_adapted_model/'+ model_file
            trained_checkpoint = torch.load(model_path, map_location=device)
            
            if isinstance(trained_checkpoint, dict) and 'model_state_dict' in trained_checkpoint:
                model.load_state_dict(trained_checkpoint['model_state_dict'], strict=False)
                print("âœ… Step01 trained model loaded successfully")
            else:
                model.load_state_dict(trained_checkpoint, strict=False)
                print("âœ… Trained model loaded successfully")
                
        except Exception as e:
            print(f"âš ï¸ Warning: Failed to load trained weights, using base model: {e}")
            print("ğŸ“‹ Using base model only")
    else:
        print("ğŸ“‹ Using base model only (as requested)")
    
    model.eval().to(device)
    torch.set_grad_enabled(False)  # å…¨ä½“ã§å‹¾é…ã‚’ç„¡åŠ¹åŒ–
    
    return model

def main(finetuned_model, model_file, test_file, out_file, batch_size=4):  # â† batch_sizeå‰Šæ¸›
    print("Loading trained model...")
    model = load_trained_model(finetuned_model=finetuned_model, model_file=model_file)
    
    # å¯¾è±¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    test_df = pd.read_csv("/mnt/s/Workfolder/vector_embedding_echo/dataset/datasplit/" + test_file)
    dicom_paths = test_df['dicom_path'].tolist()
    
    print(f"Processing {len(dicom_paths)} DICOM files with batch_size={batch_size}")
    
    # çµæœä¿å­˜ç”¨
    output_file = "/mnt/s/Workfolder/vector_embedding_echo/vedata/" + out_file + ".csv"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿
    with open(output_file, 'w') as f:
        ve_columns = [f"ve{str(i+1).zfill(3)}" for i in range(512)]
        header = ["dicom_path"] + ve_columns
        f.write(",".join(header) + "\n")
    
    # ãƒãƒƒãƒå‡¦ç†ã§embeddingæŠ½å‡ºï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
    successful_count = 0
    error_count = 0
    
    for i in tqdm(range(0, len(dicom_paths), batch_size), desc="Extracting embeddings"):
        batch_paths = dicom_paths[i:i+batch_size]
        batch_videos = []
        valid_paths = []
        
        # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿æº–å‚™
        for path in batch_paths:
            try:
                video = data_utils.process_dicom(path)
                if video is not None:
                    batch_videos.append(video)
                    valid_paths.append(path)
                else:
                    error_count += 1
            except Exception as e:
                print(f"Error processing {path}: {e}")
                error_count += 1
                continue
        
        if not batch_videos:
            continue
            
        # ãƒãƒƒãƒæ¨è«–
        try:
            batch_tensor = torch.cat(batch_videos, dim=0).to(device)
            embeddings = model.base_encoder(batch_tensor).cpu().numpy()
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
            with open(output_file, 'a') as f:
                for path, embedding in zip(valid_paths, embeddings):
                    row_data = [path] + embedding.tolist()
                    f.write(",".join(map(str, row_data)) + "\n")
            
            successful_count += len(valid_paths)
                    
        except Exception as e:
            print(f"Error in batch processing: {e}")
            error_count += len(valid_paths)
            continue
    
    # çµæœã‚µãƒãƒªãƒ¼
    total_files = successful_count + error_count
    success_rate = (successful_count / total_files * 100) if total_files > 0 else 0
    
    print(f"\nğŸ“Š Extraction Summary:")
    print(f"âœ… Successful: {successful_count}/{total_files} ({success_rate:.1f}%)")
    print(f"âŒ Errors: {error_count}")
    print(f"ğŸ’¾ Output: {output_file}")

if __name__ == "__main__":
    # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼ˆé«˜é€Ÿè¨­å®šï¼‰
    print("ğŸ”¬ Quick Fix Test (Small batches)")
    main(finetuned_model=True, model_file="echomodel_lora_quickfix.pth", 
         test_file="test_sel_ds.csv", out_file="ve_lora_quickfix", batch_size=2)
    
    main(finetuned_model=True, model_file="echomodel_lora_opt.pth", 
         test_file="test_sel_ds.csv", out_file="ve_lora_opt", batch_size=4)
    
    main(finetuned_model=False, model_file="echo_prime_encoder.pt", 
         test_file="test_sel_ds.csv", out_file="ve_echoprime_quickfix", batch_size=6)
    
    # æœ¬ç•ªå®Ÿè¡Œï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤ã—ã¦ä½¿ç”¨ï¼‰
    # print("\nğŸ­ Production Extraction")
    # main(finetuned_model=True, model_file="echomodel_lora_production.pth", 
    #      test_file="test_ds.csv", out_file="ve_lora_production", batch_size=8)
    
    # main(finetuned_model=True, model_file="echomodel_lora_adv_production.pth", 
    #      test_file="test_ds.csv", out_file="ve_lora_adv_production", batch_size=8)
    
    # main(finetuned_model=False, model_file="echo_prime_encoder.pt", 
    #      test_file="test_ds.csv", out_file="ve_echoprime_production", batch_size=8)