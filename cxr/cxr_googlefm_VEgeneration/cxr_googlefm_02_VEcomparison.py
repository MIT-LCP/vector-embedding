### Script usage ###
# Checking the embeddings generated by cxr_googlefm_01.VEgeneration.py
# Comparing the generated VE with published VE (https://physionet.org/content/image-embeddings-mimic-cxr/1.0/)

### 250210 AH


### 1. Checking the generated embedding file

import numpy as np

file_path = "/home/sagemaker-user/cxr_foundation/script/embeddings_all/embeddings_all.npz"
data = np.load(file_path)
print("Keys in the .npz file:", data.files)

# Print the shape of each stored array and preview the first 5
for key in data.files:
    print(f"{key}: shape {data[key].shape}, dtype {data[key].dtype}")
    print(f"\nFirst few values of {key}:\n", data[key][:5])

elixrc_embeddings = data['elixrc_embeddings']
elixrb_embeddings = data['elixrb_embeddings']

print("elixrc - Number of DICOM files (samples):", elixrc_embeddings.shape[0])
print("elixrc - Dimensionality per sample:", elixrc_embeddings.shape[1:])

print("elixrb - Number of DICOM files (samples):", elixrb_embeddings.shape[0])
print("elixrb - Dimensionality per sample:", elixrb_embeddings.shape[1:])


### 2. Compare the generated VE with published VE

# 2-1) Pool using GAP for comparison : elixrc embedding (N,1,8,8,1376) -> (N,1,1376) 

import numpy as np

# Load the saved embeddings
npz_file = "/home/sagemaker-user/cxr_foundation/script/embeddings_all/embeddings_all.npz"
data = np.load(npz_file, allow_pickle=True)

# Extract stored embeddings
paths = data["paths"]
elixrc_embeddings = data["elixrc_embeddings"]  # Shape: (N, 1, 8, 8, 1376)

# Apply global average pooling (or max pooling)
elixrc_embeddings_pooled = np.mean(elixrc_embeddings, axis=(2, 3))  # Shape: (N, 1, 1376)

# Save the pooled embeddings
np.savez_compressed("/home/sagemaker-user/cxr_foundation/script/embeddings_all/elixr_embeddings_pooled.npz",
                    paths=paths,
                    elixrc_embeddings=elixrc_embeddings_pooled)

print(f"✅ Processed embeddings saved as 'elixr_embeddings_pooled.npz' with shape {elixrc_embeddings_pooled.shape}")


# 2-2) compare  with published VE

import boto3
import os
import tensorflow as tf
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def construct_tfrecord_path(dicom_path, tfrecord_base_path):
    """
    Converts a .dcm S3 path from the embedding dataset into the corresponding .tfrecord S3 path.
    """
    relative_path = "/".join(dicom_path.split("/")[-4:])
    tfrecord_path = f"{tfrecord_base_path}/{relative_path}".replace(".dcm", ".tfrecord")
    return tfrecord_path

s3 = boto3.client("s3")

def s3_file_exists(s3_path):
    """Check if a file exists in S3."""
    bucket_name = s3_path.split("/")[2]
    key = "/".join(s3_path.split("/")[3:])
    try:
        s3.head_object(Bucket=bucket_name, Key=key)
        return True
    except:
        return False

def read_tfrecord_embedding(tfrecord_path):
    """Reads a TFRecord and extracts the image embedding."""
    if not s3_file_exists(tfrecord_path):
        print(f"TFRecord file not found: {tfrecord_path}")
        return None

    local_tfrecord = "/tmp/temp.tfrecord"
    s3.download_file(tfrecord_path.split("/")[2], "/".join(tfrecord_path.split("/")[3:]), local_tfrecord)
    raw_dataset = tf.data.TFRecordDataset(local_tfrecord)

    for raw_record in raw_dataset:
        example = tf.train.Example()
        example.ParseFromString(raw_record.numpy())
        key = "embedding"
        if key in example.features.feature:
            feature = example.features.feature[key].float_list.value
            return np.array(feature)

    return None

# Load the pre-pooled embeddings
pooled_data = np.load("/home/sagemaker-user/cxr_foundation/script/embeddings_all/elixr_embeddings_pooled.npz")
all_paths = pooled_data['paths']
pooled_embeddings = pooled_data['elixrc_embeddings']  # Should be shape (N, 1, 15)

# Compute cosine similarity
tfrecord_base_path = "s3://resresearcher-lcp-takeshi-group-767397697436/ah_trial/mimic_cxr_tfrecords"
cosine_similarities = []

for idx, dicom_path in enumerate(all_paths):
    # Get the pre-pooled embedding
    pooled_embedding = pooled_embeddings[idx]  # Shape (1, 15)
    
    # Flatten if needed
    if len(pooled_embedding.shape) > 2:
        pooled_embedding = pooled_embedding.reshape(1, -1)

    # Construct the correct TFRecord path
    tfrecord_path = construct_tfrecord_path(dicom_path, tfrecord_base_path)

    # Read PhysioNet embedding
    tfrecord_embedding = read_tfrecord_embedding(tfrecord_path)

    if tfrecord_embedding is None:
        print(f"❌ Skipping {dicom_path} - TFRecord missing or invalid.")
        continue

    # Reshape TFRecord embedding to match pooled embedding dimensions
    tfrecord_embedding = tfrecord_embedding.reshape(1, -1)
    
    # If dimensions don't match, we might need to adjust the TFRecord embedding
    if tfrecord_embedding.shape[1] != pooled_embedding.shape[1]:
        print(f"⚠️ Dimension mismatch: Pooled={pooled_embedding.shape}, TFRecord={tfrecord_embedding.shape}")
        continue

    # Compute cosine similarity
    cos_sim = cosine_similarity(pooled_embedding, tfrecord_embedding)[0, 0]
    cosine_similarities.append(cos_sim)

    if (idx + 1) % 50 == 0:
        print(f"Processed {idx + 1} files...")
        print(f"Current mean similarity: {np.mean(cosine_similarities):.6f}")

# Print summary statistics
print(f"\n✅ Batch Processing Completed")
print(f"Number of files processed: {len(cosine_similarities)}")
print(f"Mean Cosine Similarity: {np.mean(cosine_similarities):.6f}")
print(f"Standard Deviation: {np.std(cosine_similarities):.6f}")
print(f"Min: {np.min(cosine_similarities):.6f}")
print(f"Max: {np.max(cosine_similarities):.6f}")



# 2-3) Plotting cosine similarity distribution overlap between your embeddings

import matplotlib.pyplot as plt
import numpy as np

# Create histogram
plt.figure(figsize=(8, 5))
plt.hist(cosine_similarities, bins=10, edgecolor='black', alpha=0.7)
plt.xlabel("Cosine Similarity")
plt.ylabel("Frequency")
plt.title("Histogram of Cosine Similarity Scores")
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.show()


# 2-4) Plotting distribution overlap between your embeddings - one dicom

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

def plot_single_embedding_comparison(pooled_embedding, tfrecord_embedding, dicom_path, save_path='single_distribution_comparison.png'):
    """
    Plot the distribution comparison for a single DICOM's embeddings.
    
    Args:
        pooled_embedding: numpy array of shape (1, 15) or (15,)
        tfrecord_embedding: numpy array of matching shape
        dicom_path: path of the DICOM file for reference
        save_path: where to save the plot
    """
    # Ensure embeddings are flattened to 1D
    pooled_flat = pooled_embedding.flatten()
    tfrecord_flat = tfrecord_embedding.flatten()
    
    # Create the plot
    plt.figure(figsize=(12, 6))
    
    # Plot the distributions
    sns.kdeplot(data=pooled_flat, label='Generated Embedding', color='blue', alpha=0.5)
    sns.kdeplot(data=tfrecord_flat, label='TFRecord Embedding', color='red', alpha=0.5)
    
    # Add scatter points for actual values
    plt.scatter(pooled_flat, np.zeros_like(pooled_flat) - 0.02, 
               color='blue', alpha=0.6, marker='|', s=100, label='Generated Values')
    plt.scatter(tfrecord_flat, np.zeros_like(tfrecord_flat) - 0.04, 
               color='red', alpha=0.6, marker='|', s=100, label='TFRecord Values')
    
    # Add vertical lines for means
    plt.axvline(pooled_flat.mean(), color='blue', linestyle='--', alpha=0.5)
    plt.axvline(tfrecord_flat.mean(), color='red', linestyle='--', alpha=0.5)
    
    # Add statistics
    stats_text = (
        f'Generated Mean: {pooled_flat.mean():.3f}\n'
        f'TFRecord Mean: {tfrecord_flat.mean():.3f}\n'
        f'Generated Std: {pooled_flat.std():.3f}\n'
        f'TFRecord Std: {tfrecord_flat.std():.3f}\n'
        f'Cosine Similarity: {np.dot(pooled_flat, tfrecord_flat) / (np.linalg.norm(pooled_flat) * np.linalg.norm(tfrecord_flat)):.3f}'
    )
    plt.text(0.95, 0.95, stats_text,
             transform=plt.gca().transAxes,
             verticalalignment='top',
             horizontalalignment='right',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    # Customize the plot
    plt.title(f'Distribution of Embedding Values for Single DICOM\n{dicom_path}')
    plt.xlabel('Embedding Value')
    plt.ylabel('Density')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Save the plot
    plt.savefig(save_path)
    plt.show()
    plt.close()
    
    # Print additional statistics
    print(f'\nValue ranges:')
    print(f'Generated: [{pooled_flat.min():.3f}, {pooled_flat.max():.3f}]')
    print(f'TFRecord: [{tfrecord_flat.min():.3f}, {tfrecord_flat.max():.3f}]')

pooled_data = np.load('/home/sagemaker-user/cxr_foundation/script/embeddings_all/elixr_embeddings_pooled.npz')
pooled_embeddings = pooled_data['elixrc_embeddings']
paths = pooled_data['paths']

idx = 0  # Change this to analyze different DICOMs
single_pooled = pooled_embeddings[idx]
dicom_path = paths[idx]

tfrecord_path = construct_tfrecord_path(dicom_path, tfrecord_base_path)
tfrecord_embedding = read_tfrecord_embedding(tfrecord_path)

plot_single_embedding_comparison(single_pooled, tfrecord_embedding, dicom_path)


# 2-5) Plotting distribution overlap between your embeddings - all dicoms

# Check all DICOMs and count valid TFRecords
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

def find_valid_pairs(pooled_embeddings, paths, tfrecord_base_path, max_pairs=15):
    """
    Find valid DICOM-TFRecord pairs where TFRecord exists.
    
    Returns:
        List of tuples (idx, dicom_path, tfrecord_embedding)
    """
    valid_pairs = []
    print("Checking for valid DICOM-TFRecord pairs...")
    
    for idx in range(len(pooled_embeddings)):
        dicom_path = paths[idx]
        tfrecord_path = construct_tfrecord_path(dicom_path, tfrecord_base_path)
        tfrecord_embedding = read_tfrecord_embedding(tfrecord_path)
        
        if tfrecord_embedding is not None:
            valid_pairs.append((idx, dicom_path, tfrecord_embedding))
            print(f"✅ Found valid pair {len(valid_pairs)}: {dicom_path}")
            
            if len(valid_pairs) >= max_pairs:
                break
    
    print(f"\nFound {len(valid_pairs)} valid pairs out of {min(idx+1, len(pooled_embeddings))} checked")
    return valid_pairs

def plot_embedding_comparisons(valid_pairs, pooled_embeddings, save_path=None):
    """
    Create subplots comparing distributions for each valid pair.
    """
    num_plots = len(valid_pairs)
    fig, axes = plt.subplots(num_plots, 1, figsize=(12, 6*num_plots))
    plt.subplots_adjust(hspace=0.5)  # Add more space between plots
    
    # Handle case where only one plot is created
    if num_plots == 1:
        axes = [axes]
    
    for i, (idx, dicom_path, tfrecord_embedding) in enumerate(valid_pairs):
        ax = axes[i]
        pooled_embedding = pooled_embeddings[idx]
        
        # Flatten embeddings
        pooled_flat = pooled_embedding.flatten()
        tfrecord_flat = tfrecord_embedding.flatten()
        
        # Plot distributions
        sns.kdeplot(data=pooled_flat, label='Generated', color='blue', alpha=0.5, ax=ax)
        sns.kdeplot(data=tfrecord_flat, label='TFRecord', color='red', alpha=0.5, ax=ax)
        
        # Add scatter points for actual values
        ax.scatter(pooled_flat, np.zeros_like(pooled_flat) - 0.02, 
                  color='blue', alpha=0.6, marker='|', s=100)
        ax.scatter(tfrecord_flat, np.zeros_like(tfrecord_flat) - 0.04, 
                  color='red', alpha=0.6, marker='|', s=100)
        
        # Add statistics
        cosine_sim = np.dot(pooled_flat, tfrecord_flat) / (np.linalg.norm(pooled_flat) * np.linalg.norm(tfrecord_flat))
        stats_text = (
            f'Cosine Similarity: {cosine_sim:.3f}\n'
            f'Generated Mean: {pooled_flat.mean():.3f}\n'
            f'TFRecord Mean: {tfrecord_flat.mean():.3f}'
        )
        ax.text(0.95, 0.95, stats_text,
                transform=ax.transAxes,
                verticalalignment='top',
                horizontalalignment='right',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # Customize plot
        ax.set_title(f'Distribution for DICOM {idx}\n{dicom_path.split("/")[-1]}')
        ax.set_xlabel('Embedding Value')
        ax.set_ylabel('Density')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    if save_path:
        plt.savefig(save_path, bbox_inches='tight')
    
    plt.show()

# Usage
if __name__ == "__main__":
    # Load your data
    pooled_data = np.load('/home/sagemaker-user/cxr_foundation/script/embeddings_all/elixr_embeddings_pooled.npz')
    pooled_embeddings = pooled_data['elixrc_embeddings']
    paths = pooled_data['paths']
    
    # Find valid pairs
    tfrecord_base_path = "s3://resresearcher-lcp-takeshi-group-767397697436/ah_trial/mimic_cxr_tfrecords"
    valid_pairs = find_valid_pairs(pooled_embeddings, paths, tfrecord_base_path, max_pairs=15)
    
    if valid_pairs:
        # Create plots
        plot_embedding_comparisons(valid_pairs, pooled_embeddings, save_path='distribution_comparisons.png')
    else:
        print("❌ No valid DICOM-TFRecord pairs found")