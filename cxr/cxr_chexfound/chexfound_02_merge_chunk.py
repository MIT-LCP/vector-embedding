"""
CheXFound Embedding Chunk Merger

This script merges chunked CheXFound embeddings into consolidated files with 
EVA-X compatible format for downstream analysis pipelines.

=============================================================================
OVERVIEW
=============================================================================

Merges multiple part*.npz chunk files (output from chexfound_embedding_extraction.py)
into three consolidated embedding files:
1. CLS embeddings (1024-dim)
2. Pooled patch embeddings (1024-dim) 
3. Concatenated CLS+Pooled embeddings (2048-dim)

All outputs follow EVA-X format specification for compatibility with existing
analysis pipelines.

=============================================================================
EVA-X FORMAT SPECIFICATION
=============================================================================

Output .npz files contain two arrays:

1. **filenames**: np.ndarray
   - Shape: (N,)
   - Dtype: Unicode string (typically <U44)
   - Content: Array of DICOM IDs ['dicom_id_1', 'dicom_id_2', ...]

2. **embeddings**: np.ndarray
   - Shape: (N,)
   - Dtype: object
   - Content: Each element is a separate 1D float array
   - Element shapes:
     * CLS:    [1024] per image
     * Pooled: [1024] per image
     * Concat: [2048] per image (CLS + Pooled)

**Example Structure:**
```
.npz file
├── filenames: ['dcm1', 'dcm2', ...]  # shape (N,)
└── embeddings: [array([...]), array([...]), ...]  # shape (N,), dtype=object
                     ↑[1024]        ↑[1024]
```

**Loading Example:**
```python
data = np.load('chexfound_cls_all_evax.npz', allow_pickle=True)
filenames = data['filenames']          # (N,) string array
embeddings = data['embeddings']        # (N,) object array
single_embedding = embeddings[0]       # (1024,) float array
```

=============================================================================
INPUT REQUIREMENTS
=============================================================================

**Input Chunk Files:**
- Naming pattern: `chexfound_comb_all_part*.npz` (or custom pattern)
- Must contain keys: 'filenames', 'cls_embeddings', 'pooled_patch_embeddings'
- Generated by chexfound_embedding_extraction.py with extraction_mode='single_combined'

**Expected Chunk Structure:**
Each part*.npz file contains:
- filenames: (N,) array of DICOM IDs
- cls_embeddings: (N, 1024) float16 array
- pooled_patch_embeddings: (N, 1024) float16 array

=============================================================================
OUTPUT FILES
=============================================================================

Three consolidated .npz files are created:

1. **chexfound_cls_all_evax.npz**
   - CLS token embeddings only
   - Embedding dimension: 1024
   - Use case: Standard image-level representations

2. **chexfound_pooled_all_evax.npz**
   - Mean-pooled patch embeddings only
   - Embedding dimension: 1024
   - Use case: Alternative image-level representations

3. **chexfound_concat_all_evax.npz**
   - Concatenated CLS + Pooled embeddings
   - Embedding dimension: 2048
   - Use case: Richer combined representations

=============================================================================
USAGE EXAMPLES
=============================================================================

**Basic usage:**
```bash
python merge_chexfound_embeddings.py \
  --chunk_pattern "/path/to/chexfound_comb_all_part*.npz" \
  --output_dir "/path/to/output/"
```

**Custom output prefix:**
```bash
python merge_chexfound_embeddings.py \
  --chunk_pattern "/path/to/chunks/part*.npz" \
  --output_dir "/path/to/output/" \
  --output_prefix "mimic_chexfound"
```

**Output:** Creates 3 files:
- mimic_chexfound_cls_all_evax.npz
- mimic_chexfound_pooled_all_evax.npz
- mimic_chexfound_concat_all_evax.npz

=============================================================================
NOTES
=============================================================================

**Memory Considerations:**
- Script loads all chunks into memory before concatenation
- For very large datasets (>1M images), monitor RAM usage
- Concatenation happens in-memory but conversion to object array is sequential

**Gloria Head Compatibility:**
- CLS and Pooled outputs are NOT compatible with Gloria head
- Gloria head requires full spatial patch embeddings from last 4 layers
- For Gloria head, use extraction_mode='multilayer_full' in extraction script

**Format Compatibility:**
- Output format is identical to EVA-X embedding format
- Compatible with existing downstream analysis pipelines
- Can be directly used with EVA-X linear probe and fine-tuning scripts

=============================================================================
"""

import glob
import numpy as np
import os
import argparse
from tqdm import tqdm


def parse_args():
    """
    Parse command line arguments for embedding chunk merging.
    
    Returns:
        argparse.Namespace: Parsed arguments
    """
    parser = argparse.ArgumentParser(
        description='Merge CheXFound embedding chunks into EVA-X compatible format',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--chunk_pattern', 
        type=str, 
        required=True,
        help='Glob pattern for chunk files (e.g., "/path/to/part*.npz")'
    )
    
    parser.add_argument(
        '--output_dir', 
        type=str, 
        required=True,
        help='Directory to save merged embedding files'
    )
    
    parser.add_argument(
        '--output_prefix', 
        type=str, 
        default='chexfound',
        help='Prefix for output filenames (default: chexfound)'
    )
    
    parser.add_argument(
        '--verify_dimensions',
        action='store_true',
        help='Verify embedding dimensions match expected values (1024 for CLS/Pooled)'
    )
    
    return parser.parse_args()


def load_chunks(chunk_files):
    """
    Load all chunk files and concatenate embeddings.
    
    Args:
        chunk_files: List of paths to chunk .npz files
        
    Returns:
        tuple: (filenames, cls_array, pooled_array)
            - filenames: (N,) string array
            - cls_array: (N, 1024) float array
            - pooled_array: (N, 1024) float array
    """
    all_filenames = []
    all_cls = []
    all_pooled = []
    
    for chunk_file in tqdm(chunk_files, desc="Loading chunks"):
        data = np.load(chunk_file)
        
        if 'filenames' not in data or 'cls_embeddings' not in data or 'pooled_patch_embeddings' not in data:
            raise KeyError(f"Chunk {chunk_file} missing required keys. "
                         f"Expected: 'filenames', 'cls_embeddings', 'pooled_patch_embeddings'")
        
        all_filenames.extend(data['filenames'])
        all_cls.append(data['cls_embeddings'])
        all_pooled.append(data['pooled_patch_embeddings'])
    
    filenames = np.array(all_filenames)
    cls_array = np.concatenate(all_cls, axis=0)
    pooled_array = np.concatenate(all_pooled, axis=0)
    
    return filenames, cls_array, pooled_array


def convert_to_evax_format(array_2d):
    """
    Convert 2D array to EVA-X object array format.
    
    Args:
        array_2d: (N, D) numpy array
        
    Returns:
        np.ndarray: (N,) object array where each element is a (D,) float array
    """
    n_samples = array_2d.shape[0]
    obj_array = np.empty(n_samples, dtype=object)
    
    for i in tqdm(range(n_samples), desc="Converting to EVA-X format"):
        obj_array[i] = array_2d[i]
    
    return obj_array


def save_embedding_file(output_path, filenames, embeddings_obj):
    """
    Save embeddings in EVA-X format.
    
    Args:
        output_path: Path to output .npz file
        filenames: (N,) string array
        embeddings_obj: (N,) object array
    """
    np.savez(output_path, filenames=filenames, embeddings=embeddings_obj)
    
    file_size_mb = os.path.getsize(output_path) / (1024**2)
    print(f"Saved: {os.path.basename(output_path)} ({file_size_mb:.1f} MB)")


def verify_dimensions(cls_array, pooled_array, expected_dim=1024):
    """
    Verify that embedding dimensions match expected values.
    
    Args:
        cls_array: (N, D) CLS embeddings
        pooled_array: (N, D) Pooled embeddings
        expected_dim: Expected embedding dimension
        
    Raises:
        ValueError: If dimensions don't match expected values
    """
    if cls_array.shape[1] != expected_dim:
        raise ValueError(f"CLS embeddings have dimension {cls_array.shape[1]}, "
                        f"expected {expected_dim}")
    
    if pooled_array.shape[1] != expected_dim:
        raise ValueError(f"Pooled embeddings have dimension {pooled_array.shape[1]}, "
                        f"expected {expected_dim}")
    
    if cls_array.shape[0] != pooled_array.shape[0]:
        raise ValueError(f"CLS and Pooled have different number of samples: "
                        f"{cls_array.shape[0]} vs {pooled_array.shape[0]}")


def main():
    """
    Main execution function for merging CheXFound embedding chunks.
    """
    args = parse_args()
    
    print("\n" + "="*80)
    print("CheXFound Embedding Chunk Merger")
    print("="*80)
    print(f"Chunk pattern: {args.chunk_pattern}")
    print(f"Output directory: {args.output_dir}")
    print(f"Output prefix: {args.output_prefix}")
    print("="*80 + "\n")
    
    chunk_files = sorted(glob.glob(args.chunk_pattern))
    
    if len(chunk_files) == 0:
        raise FileNotFoundError(f"No chunks found matching pattern: {args.chunk_pattern}")
    
    print(f"Found {len(chunk_files)} chunk files\n")
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    filenames, cls_array, pooled_array = load_chunks(chunk_files)
    
    print(f"\nTotal images: {len(filenames)}")
    print(f"CLS shape: {cls_array.shape}")
    print(f"Pooled shape: {pooled_array.shape}")
    
    if args.verify_dimensions:
        print("\nVerifying dimensions...")
        verify_dimensions(cls_array, pooled_array)
        print("Dimension verification passed")
    
    concat_array = np.concatenate([cls_array, pooled_array], axis=1)
    print(f"Concatenated shape: {concat_array.shape}")
    
    print("\nConverting to EVA-X format...")
    cls_obj = convert_to_evax_format(cls_array)
    pooled_obj = convert_to_evax_format(pooled_array)
    concat_obj = convert_to_evax_format(concat_array)
    
    print("\nSaving output files...")
    
    cls_path = os.path.join(args.output_dir, f"{args.output_prefix}_cls_all_evax.npz")
    save_embedding_file(cls_path, filenames, cls_obj)
    
    pooled_path = os.path.join(args.output_dir, f"{args.output_prefix}_pooled_all_evax.npz")
    save_embedding_file(pooled_path, filenames, pooled_obj)
    
    concat_path = os.path.join(args.output_dir, f"{args.output_prefix}_concat_all_evax.npz")
    save_embedding_file(concat_path, filenames, concat_obj)
    
    print("\n" + "="*80)
    print("Merge complete! Files are EVA-X compatible.")
    print("="*80)
    print("\nUsage example:")
    print(f"  data = np.load('{cls_path}', allow_pickle=True)")
    print("  filenames = data['filenames']")
    print("  embeddings = data['embeddings']  # dtype=object")
    print("  single_embedding = embeddings[0]   # shape (1024,)")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()